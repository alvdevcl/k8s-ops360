apiVersion: v1
kind: ConfigMap
metadata: 
  name: acx-plus-metadata
  namespace: ops360
data: 
  application.conf: |-
      datastax-java-driver {
        basic.contact-points = ["cassandra.poc-demo.alveo-sandbox.net:9042"]
      
        basic.request {
          timeout = 30 seconds
        }
      
        basic.load-balancing-policy {
          local-datacenter = "dc1"
        }
      
        advanced.connection {
          pool {
            local {
              size = 32
            }
            remote {
              size = 32
            }
          }
          max-requests-per-connection = 2048
          max-orphan-requests = 800
        }
      
        advanced.retry-policy {
          class = com.assetcontrol.acx.persistence.cassandra.ConfigurableRetryPolicy
        }
      }
      
      acx-plus-tm {
        appClassId = "ACXPlusTransactionMonitor" // should always be the same
        appClassIdInstance = "TM_DEV"
        appClassIdInstance = ${?APP_CLASS_ID_INSTANCE}
      
        node-group {
          id = "NG1"
          id = ${?HOSTNAME}
      
          // types: KafkaNode (specific to LagoMessages)
          group-type = "KafkaNode"
      
          retry-kafka-config {
            enabled = true
            kafka.topic = "ac.init.retry.acx123"
            kafka.bootstrap.servers = "kafka.poc-demo.alveo-sandbox.net:9092"
            kafka.session.timeout.ms = 30000
          }
      
      
          uoiPipeKafkaConfig {
            kafka.bootstrap.servers = "kafka.poc-demo.alveo-sandbox.net:9092" 
            kafka.max.partition.fetch.bytes = 1024
            kafka.fetch.max.bytes = 1024
            kafka.max.poll.records = 10
            kafka.session.timeout.ms = 30000
            kafka.heartbeat.interval.ms = 5000
            kafka.key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
          }
      
          // delegate init strategy name (case insensitive)
          // NORMAL - normal flow (throttler delegate -> delegateToEventHandler -> registration -> operation -> deregistration)
          // DEBUG_LOG_ONLY_CHAIN - debug just log (tee delegate (logs) -> delegateToEventHandler -> tee event handler (logs))
          // see KafkaNodeDelegateInitStrategy for more options
          // DEBUG_LOG_WITH_THROTTLING_CHAIN - similar to normal expcept the the operation handler is replaced with a logging
          // tee handler (throttler delegate -> delegateToEventHandler -> registration -> tee handler (log) -> deregistration)
          kafkaNodeDelegateInitStrategy = "NORMAL"
      
          // limit on the context reactor queue
          contextReactorQueueCapacity = 10000
      
          // number of fixed threads in the context thread pool
          contextThreadPoolSize = 10000
      
          // maximum number of tasks in wait in the context pool queue
          contextThreadPoolQueueCapacity = 10000
      
          // context scheduler core pool size
          contextSchedulerCorePoolSize = 4
      
          // context scheduler queue capacity
          contextSchedulerQueueCapacity = 10000
      
          // description of node families
          // family = "metadata" | "derived" | "txn"
          node-families: [
            {
              family = metadata
              instances = 1
      
              kafka.bootstrap.servers = "kafka.poc-demo.alveo-sandbox.net:9092"
              kafka.topic = ac.init.metadata.acx123
              kafka.pollTimeoutMS = 30000
              kafka.group.id = acx123-MD
              kafka.group.id = ${?KAFKA_GROUP_ID}
              kafka.max.partition.fetch.bytes = 157286400
              kafka.fetch.max.bytes = 314572800
              kafka.max.poll.records = 100
              kafka.auto.offset.reset = "earliest"
              kafka.session.timeout.ms = 60000
              kafka.heartbeat.interval.ms = 20000
            }
          ]
      
          kafka-throttler: {
            maxBytes = 314572800
            maxMessageCount = 600
          }
      
          consistency-engine: {
            maxSize = 10000
            maxBusyWaitMs = 5000
            busyWaitCheckAfterMs = 10000
            checksPeriodMs = 5000
            expiry = 600000
          }
      
          continuous-retry: {
            logErrorAfterRetries = 30
            pauseBetweenRetriesMillis = 100
            giveUpAfterMillis = 600000
          }
      
          core {
              include "/acx/config/common/core.conf"
          }
      
          merkleTreeController {
              store {
                  type = "restauth"
                  apiHosts = "http://acx-merkle-rest-service.ops360:1080/v1"
                  username = ${?MERKLE_CONTROLLER_STORE_USERNAME}
                  password = ${?MERKLE_CONTROLLER_STORE_PASSWORD}
                  expirationSeconds = "86400"
                  pauseBetweenRetries = "500"
              }
          }
        }
      }
  application.ini: |-
      -J-javaagent:/opt/agent/jmx_prometheus_javaagent-0.11.0.jar=9999:/opt/agent/config.yaml
      # Remote Debugging
      -J-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5705
      
      # Setting -X directly (-J is stripped)
      # -J-X
      
      -J-XX:+UseG1GC
      -J-Xmx3G
      -J-Xms3G
      -J-XX:+UseStringDeduplication
      -J-XX:+OptimizeStringConcat
      
      -J-XX:+HeapDumpOnOutOfMemoryError
      -J-XX:HeapDumpPath=/acx/heap/java_pid<pid>.hprof
      -J-XX:+UseGCOverheadLimit
      
      # Add additional jvm parameters
      # -Dkey=val
      
      -Dconfig.file=/acx/config/app/application.conf
      -Darchaius.configurationSource.additionalUrls=file:///acx/config/common/solr.properties
      
      # Log4j2 Configuration
      -Dlog4j2.configurationFile=/acx/config/common/log4j2.xml
      -Dlog4j2.disable.jmx=true
      
      # Hazelcast Configuration
      -Dhazelcast.shutdownhook.policy=GRACEFUL
      -Dhazelcast.logging.type=log4j2
      
      # Don't run the java version check
      # -no-version-check
      
      # enabling debug and sending -d as app argument
      # the '--' prevents app-parameter swallowing when
      # using a reserved parameter. See #184
      # -d -- -d
      -- -d64

